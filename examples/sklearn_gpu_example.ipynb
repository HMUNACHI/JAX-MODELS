{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nanodl import GaussianMixtureModel\n",
    "\n",
    "# Generate synthetic data using JAX\n",
    "def generate_data(seed=0):\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    n_samples = 300\n",
    "    mean1 = jnp.array([0, 0])\n",
    "    cov1 = jnp.array([[1, 0], [0, 1]])\n",
    "    data1 = jax.random.multivariate_normal(key, mean1, cov1, (n_samples,))\n",
    "\n",
    "    mean2 = jnp.array([3, 3])\n",
    "    cov2 = jnp.array([[1, -0.5], [-0.5, 1]])\n",
    "    data2 = jax.random.multivariate_normal(key, mean2, cov2, (n_samples,))\n",
    "\n",
    "    X = jnp.vstack([data1, data2])\n",
    "    return X\n",
    "\n",
    "# Generate data\n",
    "X = generate_data()\n",
    "\n",
    "# Fit the model\n",
    "gmm = GaussianMixtureModel(n_components=2, seed=42)\n",
    "gmm.fit(X)\n",
    "\n",
    "# Plot the data and the estimated means\n",
    "plt.scatter(X[:, 0], X[:, 1], s=10, label='Data')\n",
    "plt.scatter(gmm.means[:, 0], gmm.means[:, 1], color='red', label='Estimated Means')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.title('Gaussian Mixture Model (JAX)')\n",
    "plt.show()\n",
    "\n",
    "# Print estimated parameters\n",
    "print(\"Estimated Means:\", gmm.means)\n",
    "print(\"Estimated Covariances:\", gmm.covariances)\n",
    "print(\"Estimated Weights:\", gmm.weights)\n",
    "\n",
    "labels = X.predict(X)\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanodl import PCA\n",
    "\n",
    "# Create dummy data\n",
    "data = jax.random.normal(jax.random.key(0), (1000, 10))\n",
    "\n",
    "# Create an instance of the PCA class\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit the model\n",
    "pca.fit(data)\n",
    "\n",
    "# Transform the data to the new lower dimension space\n",
    "transformed_data = pca.transform(data)\n",
    "\n",
    "# Inverse transform the data to the original space\n",
    "original_data = pca.inverse_transform(transformed_data)\n",
    "\n",
    "# Sample from the model\n",
    "X_sampled = pca.sample(n_samples=1000, key=None)\n",
    "\n",
    "print(X_sampled.shape, original_data.shape, transformed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanodl import LogisticRegression\n",
    "\n",
    "num_samples = 100\n",
    "input_dim = 2\n",
    "\n",
    "x_data = jax.random.normal(jax.random.PRNGKey(0), (num_samples, input_dim))\n",
    "logits = jnp.dot(x_data, jnp.array([0.5, -0.5])) - 0.1\n",
    "y_data = (logits > 0).astype(jnp.float32)\n",
    "\n",
    "lr_model = LogisticRegression(input_dim)\n",
    "lr_model.train(x_data, y_data)\n",
    "\n",
    "test_data = jax.random.normal(jax.random.PRNGKey(0), (num_samples, input_dim))\n",
    "predictions = lr_model.predict(test_data)\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
